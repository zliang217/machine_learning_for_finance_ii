{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l163joRD2Jls"
      },
      "source": [
        "# PyTorch Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jEYF0Nbl2Jop"
      },
      "source": [
        "## PyTorch\n",
        "\n",
        "What is PyTorch?\n",
        "\n",
        "It’s a Python-based scientific computing package targeted at two sets of audiences:\n",
        "\n",
        "* A replacement for NumPy to use the power of GPUs\n",
        "* a deep learning research platform that provides maximum flexibility and speed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gCluOwzJ2Joq"
      },
      "source": [
        "### Tensors\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qvgMuRFh2Joq"
      },
      "source": [
        "PyTorch provides functions similar to numpy to create tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9SM8dVJh2Joq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\chinm\\miniconda3\\envs\\ml_finance\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: DLL load failed while importing _multiarray_umath: The specified module could not be found. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
            "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
          ]
        }
      ],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Uu2AUayb2Jor",
        "outputId": "8962e835-d616-4928-dcbe-2c3addaf35e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[4.8485e-27, 1.4027e-42, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "x = torch.empty(2, 3) # Construct a 5x3 matrix, uninitialized\n",
        "print(x)\n",
        "print(x.size()) # torch.Size is a tuple, so it supports all tuple operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vylcMhQE2Jos",
        "outputId": "9f198a77-e300-4e57-9c9e-efb53d0f7484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0404, 0.0793, 0.3350],\n",
            "        [0.3403, 0.1045, 0.5564]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(2, 3) # Construct a randomly initialized matrix\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LSglEAJy2Jot",
        "outputId": "e7a27d4c-5d27-4022-9d24-5fea7ad8f9ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long) # Construct a matrix filled zeros and of dtype long\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2mpsMSiN2Jou",
        "outputId": "4003b2d3-7aaa-4652-84f1-f6374baf8e94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([5.5, 3]) # Construct a tensor directly from data\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HQak9CAP2Jov",
        "outputId": "751dea06-2668-4c3a-f3e5-e88731264215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[-1.9743,  1.5456,  0.5493],\n",
            "        [ 1.6086, -0.5135, -0.5834]])\n"
          ]
        }
      ],
      "source": [
        "# create a tensor based on an existing tensor. These methods will reuse properties of the input tensor, e.g. dtype, unless new values are provided by user\n",
        "x = x.new_ones(2, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S01zJDNR2Jox"
      },
      "source": [
        "### Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QUcSOSZe2Joy"
      },
      "source": [
        "There are multiple syntaxes for operations. In the following example, we will take a look at the addition operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "G1DynQnm2Joz",
        "outputId": "053ddea2-0009-49bc-d3e1-5968b50b6f4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.9007,  2.3200,  0.7025],\n",
            "        [ 1.6093,  0.2891, -0.3095]])\n",
            "tensor([[-1.9007,  2.3200,  0.7025],\n",
            "        [ 1.6093,  0.2891, -0.3095]])\n",
            "tensor([[-1.9007,  2.3200,  0.7025],\n",
            "        [ 1.6093,  0.2891, -0.3095]])\n",
            "tensor([[-1.9007,  2.3200,  0.7025],\n",
            "        [ 1.6093,  0.2891, -0.3095]])\n"
          ]
        }
      ],
      "source": [
        "y = torch.rand(2, 3)\n",
        "print(x + y)\n",
        "\n",
        "print(torch.add(x, y))\n",
        "\n",
        "result = torch.empty(2, 3)\n",
        "torch.add(x, y, out=result) # Providing an output tensor as argument\n",
        "print(result)\n",
        "\n",
        "y.add_(x) # In-place addition\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cRMEMkyg2Jo0"
      },
      "source": [
        "Any operation that mutates a tensor in-place is post-fixed with an \\_. For example: x.copy_(y), x.t_(), will change x."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0X2tBsQ62Jo0"
      },
      "source": [
        "### Indexing\n",
        "\n",
        "You can use standard numpy-like indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q9hBrbj22Jo0"
      },
      "source": [
        "If you have a one element tensor, use .item() to get the value as a Python number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Jg66igYP2Jo1",
        "outputId": "9cad025e-b8aa-4514-d617-176e6b4d6115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.5335])\n",
            "-0.5334818959236145\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bx2hGJU12Jo2"
      },
      "source": [
        "**Read later:**\n",
        "\n",
        "\n",
        "  100+ Tensor operations, including transposing, indexing, slicing,\n",
        "  mathematical operations, linear algebra, random numbers, etc.,\n",
        "  are described here <https://pytorch.org/docs/torch>.\n",
        "\n",
        "### NumPy Bridge\n",
        "\n",
        "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
        "\n",
        "The Torch Tensor and NumPy array will share their underlying memory\n",
        "locations, and changing one will change the other.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qGoV2xC32Jo2",
        "outputId": "af18b092-0c9f-4c16-bac5-541813f89a74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Numpy is not available",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[1;32m----> 4\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Converts torch tensor to numpy array\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(b)\n\u001b[0;32m      7\u001b[0m a\u001b[38;5;241m.\u001b[39madd_(\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\chinm\\miniconda3\\envs\\ml_finance\\Lib\\site-packages\\torch\\_tensor.py:1083\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "b = np.array(a) # Converts torch tensor to numpy array\n",
        "print(b)\n",
        "\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tVV33BAe2Jo3",
        "outputId": "7c9bb9ed-4e73-4ce2-c46c-9bb9b5b4b2cc",
        "scrolled": true
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Numpy is not available",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Converts numpy array to torch tensor\u001b[39;00m\n\u001b[0;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39madd(a, \u001b[38;5;241m1\u001b[39m, out\u001b[38;5;241m=\u001b[39ma)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a) # Converts numpy array to torch tensor\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eHmQkJCC2Jo4"
      },
      "source": [
        "### CUDA Tensor\n",
        "Tensors can be moved onto any device using the .to method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SLndMbNO2Jo4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.4665], device='cuda:0')\n",
            "tensor([0.4665], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hykmfZQW2Jo5"
      },
      "source": [
        "### Linear Regression example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YCqdANGx2Jo5"
      },
      "source": [
        "torch.nn is a Neural Network package useful for constructing models which provides layers, activation functions, loss functions, etc. ( https://github.com/torch/nn )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ioXWhTsp2Jo5"
      },
      "outputs": [],
      "source": [
        "from itertools import count\n",
        "\n",
        "import torch\n",
        "import torch.autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QZka4lk12Jo6"
      },
      "source": [
        "Define a polynomial function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6KmxvfEr2Jo6"
      },
      "outputs": [],
      "source": [
        "POLY_DEGREE = 4\n",
        "W_target = torch.randn(POLY_DEGREE, 1) * 5\n",
        "b_target = torch.randn(1) * 5\n",
        "\n",
        "def f(x):\n",
        "    \"\"\"Approximated function.\"\"\"\n",
        "    return x.mm(W_target) + b_target.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TERvrPDA2Jo7"
      },
      "source": [
        "Data loader and other utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "elWq2-oX2Jo7"
      },
      "outputs": [],
      "source": [
        "def make_features(x):\n",
        "    \"\"\"Builds features i.e. a matrix with columns [x, x^2, x^3, x^4].\"\"\"\n",
        "    x = x.unsqueeze(1)\n",
        "    return torch.cat([x ** i for i in range(1, POLY_DEGREE+1)], 1)\n",
        "\n",
        "def get_batch(batch_size=32):\n",
        "    \"\"\"Builds a batch i.e. (x, f(x)) pair.\"\"\"\n",
        "    random = torch.randn(batch_size)\n",
        "    X = make_features(random)\n",
        "    y = f(X)\n",
        "    return X, y\n",
        "\n",
        "def poly_desc(W, b):\n",
        "    \"\"\"Creates a string description of a polynomial.\"\"\"\n",
        "    result = 'y = '\n",
        "    for i, w in enumerate(W):\n",
        "        result += '{:+.2f} x^{} '.format(w, len(W) - i)\n",
        "    result += '{:+.2f}'.format(b[0])\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eWHfnx--2Jo7"
      },
      "source": [
        "Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qSw046BT2Jo8"
      },
      "outputs": [],
      "source": [
        "# Define model\n",
        "model = nn.Linear(W_target.size(0), 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jX1YK2rO2Jo8"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9VV-ve6A2Jo8",
        "outputId": "e8ed9cde-4615-44e0-8e8f-8a780f40942a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.000800 after 455 batches\n",
            "==> Learned function:\ty = +0.96 x^4 +0.81 x^3 -9.24 x^2 -1.99 x^1 +4.56\n",
            "==> Actual function:\ty = +1.00 x^4 +0.86 x^3 -9.26 x^2 -2.02 x^1 +4.56\n"
          ]
        }
      ],
      "source": [
        "for batch_idx in count(1):\n",
        "    # Get data\n",
        "    batch_x, batch_y = get_batch()\n",
        "\n",
        "    # Reset gradients\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    output = F.smooth_l1_loss(model(batch_x), batch_y)\n",
        "    loss = output.item()\n",
        "\n",
        "    # Backward pass\n",
        "    output.backward()\n",
        "    \n",
        "    # Apply gradients\n",
        "    for param in model.parameters():\n",
        "        param.data.add_(-0.1 * param.grad.data)\n",
        "\n",
        "    # Stop criterion\n",
        "    if loss < 1e-3:\n",
        "        break\n",
        "\n",
        "print('Loss: {:.6f} after {} batches'.format(loss, batch_idx))\n",
        "print('==> Learned function:\\t' + poly_desc(model.weight.view(-1), model.bias))\n",
        "print('==> Actual function:\\t' + poly_desc(W_target.view(-1), b_target))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "991ChjrP2Jo9"
      },
      "source": [
        "### Other Resources\n",
        "\n",
        "Here are some other useful resources on PyTorch\n",
        "\n",
        "* https://cs230-stanford.github.io/pytorch-getting-started.html\n",
        "* https://github.com/jcjohnson/pytorch-examples\n",
        "* https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "01_basics_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
